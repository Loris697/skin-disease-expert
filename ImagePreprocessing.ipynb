{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587722d4-c179-4e99-97cd-f12798ef1d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fourier_transform(image, show = False):\n",
    "    \n",
    "    # Apply Fourier Transform\n",
    "    f = np.fft.fft2(image)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1)  # Adding 1 to avoid log(0)\n",
    "\n",
    "    # Calculate the average values in the high-frequency areas\n",
    "    rows, cols = image.shape\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    high_freq_magnitude = magnitude_spectrum[crow-30:crow+30, ccol-30:ccol+30]\n",
    "\n",
    "    # Define blurriness based on threshold\n",
    "    mean_magnitude = np.mean(high_freq_magnitude)\n",
    "\n",
    "    if show:\n",
    "        # Display the original image and magnitude spectrum\n",
    "        plt.subplot(121), plt.imshow(image, cmap='gray')\n",
    "        plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "        \n",
    "        plt.subplot(122), plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "        plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "    return mean_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7053ab99-7087-4561-934a-c6c7539ff355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wavelet_transform(image, wavelet='db4', show = False):\n",
    "    # Compute wavelet transform\n",
    "    coeffs2 = pywt.dwt2(image, wavelet)\n",
    "    cA, (cH, cV, cD) = coeffs2\n",
    "\n",
    "    # Compute the Wavelet Transform of the image\n",
    "    coeffs2 = pywt.dwt2(image, wavelet)\n",
    "    _, (cH, cV, cD) = coeffs2\n",
    "\n",
    "    # Measure the energy of the detail coefficients\n",
    "    energy = np.sum(cH**2) + np.sum(cV**2) + np.sum(cD**2)\n",
    "\n",
    "    # Normalize by the size of the detail coefficients\n",
    "    energy /= (cH.size + cV.size + cD.size)\n",
    "\n",
    "    if show:\n",
    "        # Plotting the original image and coefficients\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        plt.subplot(141), plt.imshow(image, cmap='gray'), plt.title('Original Image'), plt.axis('off')\n",
    "        plt.subplot(142), plt.imshow(cA, cmap='gray'), plt.title('Approximation'), plt.axis('off')\n",
    "        plt.subplot(143), plt.imshow(cH, cmap='gray'), plt.title('Horizontal Detail'), plt.axis('off')\n",
    "        plt.subplot(144), plt.imshow(cV, cmap='gray'), plt.title('Vertical Detail'), plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe36024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_blurriness(image):    \n",
    "    # Apply the Laplacian filter\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    \n",
    "    # Compute the variance of the Laplacian\n",
    "    variance = laplacian.var()\n",
    "    \n",
    "    return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6717be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(folder_path):\n",
    "    \n",
    "    data = {\n",
    "        \"image\" : [],\n",
    "        \"laplacian\" : [],\n",
    "        \"fourier\" : [],\n",
    "        \"wavelet\" : []\n",
    "    }\n",
    "    \n",
    "    # Loop through all images in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Read the image\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path, 0)\n",
    "\n",
    "            # Apply Laplacian filter and compute blurriness\n",
    "            blurriness = laplacian_blurriness(image)\n",
    "            fourier = apply_fourier_transform(image)\n",
    "            wavelet = apply_wavelet_transform(image)\n",
    "\n",
    "            # Save the scalar value in output\n",
    "            data[\"image\"].append(filename)\n",
    "            data[\"laplacian\"].append(blurriness)\n",
    "            data[\"fourier\"].append(fourier)\n",
    "            data[\"wavelet\"].append(wavelet)\n",
    "            \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84bbb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(image_blur_tuples, percentile_low=1, percentile_high=100):\n",
    "    # Convert blur_values to a NumPy array for percentile calculation\n",
    "    blur_values = np.array([item[1] for item in image_blur_tuples])\n",
    "\n",
    "    # Calculate lower and upper bounds based on percentiles\n",
    "    lower_bound = np.percentile(blur_values, percentile_low)\n",
    "    upper_bound = np.percentile(blur_values, percentile_high)\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = [(name, blur) for name, blur in image_blur_tuples if blur < lower_bound or blur > upper_bound]\n",
    "\n",
    "    # Print the names and blur values of outliers\n",
    "    for name, blur in outliers:\n",
    "        print(f\"Image: {name}, Blurriness: {blur}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc5412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_images(image_blur_tuples, input_folder, top_n=16, reverse = False):\n",
    "    # Sort the tuples based on blur values in descending order\n",
    "    sorted_tuples = sorted(image_blur_tuples, key=lambda x: x[1], reverse=reverse)\n",
    "\n",
    "    # Take the top N tuples\n",
    "    top_tuples = sorted_tuples[:top_n]\n",
    "    num_row = top_n // 4\n",
    "\n",
    "    # Plot the images in a 4 by 4 grid\n",
    "    fig, axes = plt.subplots(num_row, 4, figsize=(40, num_row * 10))\n",
    "\n",
    "    for i, (name, blur) in enumerate(top_tuples):\n",
    "        # Load and plot the image\n",
    "        image_path = input_folder + name \n",
    "        image = cv2.imread(image_path)\n",
    "        axes[i // 4, i % 4].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        axes[i // 4, i % 4].set_title(f\"Blur: {blur:.2f} of image {name} \" )\n",
    "        axes[i // 4, i % 4].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e1087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(image_blur_tuples):\n",
    "    # Extract blur values from the tuple list\n",
    "    blur_values = np.array([item[1] for item in image_blur_tuples])\n",
    "\n",
    "    # Calculate common statistics\n",
    "    mean_blur = np.mean(blur_values)\n",
    "    median_blur = np.median(blur_values)\n",
    "    std_dev_blur = np.std(blur_values)\n",
    "    min_blur = np.min(blur_values)\n",
    "    max_blur = np.max(blur_values)\n",
    "\n",
    "    # Print the statistics\n",
    "    print(f\"Mean Blur: {mean_blur:.2f}\")\n",
    "    print(f\"Median Blur: {median_blur:.2f}\")\n",
    "    print(f\"Standard Deviation of Blur: {std_dev_blur:.2f}\")\n",
    "    print(f\"Minimum Blur: {min_blur:.2f}\")\n",
    "    print(f\"Maximum Blur: {max_blur:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_blur(image_name, input_folder, image_blur_tuples):\n",
    "    # Find the tuple with the specified image name\n",
    "    matching_tuple = next((item for item in image_blur_tuples if item[0] == image_name), None)\n",
    "\n",
    "    if matching_tuple:\n",
    "        # Load and plot the image\n",
    "        image_path =input_folder + matching_tuple[0]\n",
    "        image = cv2.imread(image_path)\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Image: {image_name}\\nBlur: {matching_tuple[1]:.2f}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Image with name '{image_name}' not found in the tuple list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fdeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISIC = pd.read_csv(\"DataFrames/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '../../Datasets/ISIC/ISIC_2019_Training_Input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df14485-0e10-461d-bc98-76bf1f0091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"DataFrames/preprocessing_results.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = process_images(input_folder)\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b95e8-65df-4b59-bccd-c438a42ac7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"DataFrames/preprocessing_results.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e806596-064b-4c8e-8610-858975a3fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'image' column before applying Standard Scaler\n",
    "results_to_scale = results.drop(columns=['image'])\n",
    "\n",
    "# Applying Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(results_to_scale)\n",
    "\n",
    "# Summing the scaled columns\n",
    "results_scaled = pd.DataFrame(scaled_data, columns=results_to_scale.columns)\n",
    "results_scaled['sum'] = results_scaled.sum(axis=1)\n",
    "\n",
    "# Adding the 'image' column back to the DataFrame\n",
    "results_scaled['image'] = results['image']\n",
    "\n",
    "results_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8285740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    print(column)\n",
    "    \n",
    "    data = list(zip(list(results_scaled[\"image\"]), list(results_scaled[column])))\n",
    "    plot_top_images(data, input_folder, top_n=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e6086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    print(column)\n",
    "    \n",
    "    data = list(zip(list(results[\"image\"]), list(results[column])))\n",
    "    plot_top_images(data, input_folder, top_n=16, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0027a38-62f6-459c-a4ac-431358449496",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"laplacian\", \"fourier\", \"wavelet\", \"sum\"]\n",
    "\n",
    "low_images = pd.DataFrame()\n",
    "\n",
    "for column in columns:\n",
    "    low_images = pd.concat([low_images, results_scaled.sort_values(column).head(50)], axis = 0)\n",
    "\n",
    "low_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6afca8-3259-4578-8a63-34e12befe843",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "new_directory = os.path.join(desktop_path, \"BlurredImages\")\n",
    "\n",
    "if not os.path.exists(new_directory):\n",
    "    os.makedirs(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c71ec-fe66-42d3-8558-cce914e69cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in np.unique(low_images.image):\n",
    "    source_file = '/data/cino/Datasets/ISIC/ISIC_2019_Training_Input/' + img_name \n",
    "    destination_file = os.path.join(new_directory, img_name)\n",
    "    shutil.copy(source_file, destination_file)\n",
    "\n",
    "print(f\"Images copied to {new_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af7247-0bf3-4ec9-a1b0-7f1ff3db3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually selected images\n",
    "for img_name in [\"ISIC_0010021.jpg\",\"ISIC_0025950.jpg\",\"ISIC_0026121.jpg\",\"ISIC_0026894.jpg\",\"ISIC_0026991.jpg\",\"ISIC_0027181.jpg\",\"ISIC_0029098.jpg\",\"ISIC_0030291.jpg\",\"ISIC_0033408.jpg\",\"ISIC_0033535.jpg\",\"ISIC_0062612.jpg\",\"ISIC_0063587.jpg\",\"ISIC_0065099.jpg\",\"ISIC_0067400.jpg\",\"ISIC_0067686.jpg\",\"ISIC_0069507.jpg\",\"ISIC_0071438.jpg\",\"ISIC_0072611.jpg\"]:\n",
    "    source_file = '/data/cino/Datasets/ISIC/ISIC_2019_Training_Input/' + img_name \n",
    "    destination_file = os.path.join(new_directory, img_name)\n",
    "    shutil.copy(source_file, destination_file)\n",
    "\n",
    "print(f\"Images copied to {new_directory}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
