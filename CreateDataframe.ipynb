{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:06:09.730119Z",
     "start_time": "2021-07-07T15:06:08.253462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/cino/conda/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/data/cino/conda/anaconda3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c107SymBool10guard_boolEPKcl'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import copy\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, './myCode')\n",
    "from PLModel import PLModel\n",
    "from CustomDataset import TotalDataset\n",
    "from utils import loadModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:06:09.794118Z",
     "start_time": "2021-07-07T15:06:09.789185Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "gpus = [0]\n",
    "BATCH_SIZE = 16 * len(gpus)\n",
    "batches = round(512 / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:06:09.921289Z",
     "start_time": "2021-07-07T15:06:09.795948Z"
    }
   },
   "outputs": [],
   "source": [
    "skinDataset = []\n",
    "labelName = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\"]\n",
    "\n",
    "i = 0\n",
    "#Reading the labels\n",
    "df = pandas.read_csv(\"DataFrames/label.csv\")\n",
    "#shuffling the dataframe\n",
    "df = shuffle(df, random_state=1234).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSizePerCNN = {\n",
    "    \"Resnext50\" : 600,\n",
    "    \"Resnet152\" : 600,\n",
    "    \"EfficientNetB7\": 600,\n",
    "    \"EfficientNetB6\": 528,\n",
    "    \"EfficientNetB5\": 456,\n",
    "    \"EfficientNetB4\": 380,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:06:10.005026Z",
     "start_time": "2021-07-07T15:06:09.999541Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TotalDataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models pythorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:06:11.846875Z",
     "start_time": "2021-07-07T15:06:11.818825Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "Models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T13:52:15.496620Z",
     "start_time": "2021-07-06T13:52:15.283775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "No loss specified, using default\n"
     ]
    }
   ],
   "source": [
    "model = PLModel('EfficientNetB4', EfficientNet.from_pretrained('efficientnet-b4', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "No loss specified, using default\n"
     ]
    }
   ],
   "source": [
    "model = PLModel('EfficientNetB5', EfficientNet.from_pretrained('efficientnet-b5', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n",
      "No loss specified, using default\n"
     ]
    }
   ],
   "source": [
    "model = PLModel('EfficientNetB6', EfficientNet.from_pretrained('efficientnet-b6', num_classes=8))\n",
    "Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T14:46:34.441503Z",
     "start_time": "2021-07-07T14:46:34.057839Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /data/cino/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No loss specified, using default\n"
     ]
    }
   ],
   "source": [
    "resnext = torch.hub.load('pytorch/vision:v0.9.0', 'resnext50_32x4d', pretrained=True)\n",
    "num_f = resnext.fc.in_features\n",
    "resnext.fc = nn.Linear(num_f, 8)\n",
    "Models.append(PLModel('Resnext50', resnext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T14:46:48.727433Z",
     "start_time": "2021-07-07T14:46:47.207403Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /data/cino/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No loss specified, using default\n"
     ]
    }
   ],
   "source": [
    "resnext = torch.hub.load('pytorch/vision:v0.9.0', 'resnet152', pretrained=True)\n",
    "num_f = resnext.fc.in_features\n",
    "resnext.fc = nn.Linear(num_f, 8)\n",
    "Models.append(PLModel('Resnet152', resnext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool2d(output_size=1)\n",
      "AdaptiveAvgPool2d(output_size=1)\n",
      "AdaptiveAvgPool2d(output_size=1)\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "activation = {}\n",
    "\n",
    "for model in Models:\n",
    "    if model.name.find(\"EfficientNet\") > -1:\n",
    "        print(model.model._avg_pooling)\n",
    "        model.model._avg_pooling.register_forward_hook(get_activation('avgpool'))\n",
    "    else:\n",
    "        print(model.model.avgpool)\n",
    "        model.model.avgpool.register_forward_hook(get_activation('avgpool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = [model.name for model in Models ]\n",
    "classes = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\"]\n",
    "# Creating a MultiIndex for columns\n",
    "columns = pandas.MultiIndex.from_product([models_name, classes], names=['Model', 'Label'])\n",
    "\n",
    "# Create the DataFrame with MultiIndex columns and the image index\n",
    "predictions = pandas.DataFrame(index=dataset.label.image, columns=columns)\n",
    "activations = pandas.DataFrame(index=dataset.label.image, columns=columns)\n",
    "hidden_layer = pandas.DataFrame(index=dataset.label.image, columns=models_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = pandas.read_csv(\"DataFrames/activations.csv\",header=[0, 1], index_col = 0)\n",
    "predictions = pandas.read_csv(\"DataFrames/probabilities.csv\",header=[0, 1], index_col = 0)\n",
    "hidden_layer = pandas.read_csv(\"DataFrames/last_hidden_layer.csv\",header=[0], index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/EfficientNetB4_0Fold\n",
      "checkpoints/EfficientNetB4_1Fold\n",
      "checkpoints/EfficientNetB4_2Fold\n",
      "checkpoints/EfficientNetB4_3Fold\n",
      "checkpoints/EfficientNetB4_4Fold\n",
      "checkpoints/EfficientNetB5_0Fold\n",
      "checkpoints/EfficientNetB5_1Fold\n",
      "checkpoints/EfficientNetB5_2Fold\n",
      "checkpoints/EfficientNetB5_3Fold\n",
      "checkpoints/EfficientNetB5_4Fold\n",
      "checkpoints/EfficientNetB6_0Fold\n",
      "checkpoints/EfficientNetB6_1Fold\n",
      "checkpoints/EfficientNetB6_2Fold\n",
      "checkpoints/EfficientNetB6_3Fold\n",
      "checkpoints/EfficientNetB6_4Fold\n",
      "checkpoints/Resnext50_0Fold\n",
      "checkpoints/Resnext50_1Fold\n",
      "checkpoints/Resnext50_2Fold\n",
      "checkpoints/Resnext50_3Fold\n",
      "Model Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Resnext50 - Fold 3: 100%|████████| 5067/5067 [24:48<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/Resnext50_4Fold\n",
      "Model Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Resnext50 - Fold 4: 100%|████████| 5059/5059 [25:38<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/Resnet152_0Fold\n",
      "Model Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Resnet152 - Fold 0: 100%|████████| 5067/5067 [41:16<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/Resnet152_1Fold\n",
      "Model Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Resnet152 - Fold 1: 100%|████████| 5067/5067 [41:12<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/Resnet152_2Fold\n",
      "Model Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Resnet152 - Fold 2: 100%|████████| 5067/5067 [41:06<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/Resnet152_3Fold\n",
      "Model Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Resnet152 - Fold 3: 100%|████████| 5067/5067 [39:20<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/Resnet152_4Fold\n",
      "Model Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Resnet152 - Fold 4: 100%|████████| 5059/5059 [39:19<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for model in Models:\n",
    "    dataset = TotalDataset(df, imageSize = imageSizePerCNN[model.name])\n",
    "    \n",
    "    kFolds = dataset.getKFolds()\n",
    "    for k, (_, validationDataset) in enumerate(kFolds):\n",
    "        mypath = 'checkpoints/' + model.name + '_' + str(k) + 'Fold'\n",
    "\n",
    "        print(mypath)\n",
    "        ## Checking if the prediction is already done\n",
    "        if not predictions.loc[validationDataset.label.image.values, (model.name, slice(None))].isna().any().any():\n",
    "            continue\n",
    "\n",
    "        #loading the model\n",
    "        weights_paths = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "        weights_path = weights_paths[0]\n",
    "        weights_path = mypath + \"/\" + weights_path\n",
    "        model = loadModelCheckpoint(weights_path, model)\n",
    "        \n",
    "        model.eval()        \n",
    "\n",
    "        #Calculate the predictions\n",
    "        for index, image_name in tqdm(zip(validationDataset.label.index, validationDataset.label.image.values), \n",
    "                                       total=len(validationDataset.label.index), \n",
    "                                       desc=f'Validating {model.name} - Fold {k}'):\n",
    "            image, _ = validationDataset[index]\n",
    "            output = model(image.unsqueeze(0))\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            last_cnn_hidden = json.dumps(np.array(activation['avgpool'].to('cpu')).reshape(-1).tolist())\n",
    "            activations.loc[image_name, (model.name, slice(None))] = output.detach().numpy()\n",
    "            predictions.loc[image_name, (model.name, slice(None))] = probabilities.detach().numpy()\n",
    "            hidden_layer.loc[image_name, model.name] = last_cnn_hidden\n",
    "\n",
    "        #saving the results\n",
    "        predictions.to_csv('DataFrames/probabilities.csv')\n",
    "        activations.to_csv('DataFrames/activations.csv')\n",
    "        hidden_layer.to_csv('DataFrames/last_hidden_layer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('DataFrames/probabilities.csv')\n",
    "activations.to_csv('DataFrames/activations.csv')\n",
    "hidden_layer.to_csv('DataFrames/last_hidden_layer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
